# Sistema de Evaluaciones Educativas - Dise√±o de Arquitectura

## Principios de Dise√±o

Mi dise√±o busca ser pragm√°tico. Estas son mis motivaciones para cada decisi√≥n:

- **Simplicidad Operativa:** Priorizo productos gestionados (Managed Services) en lugar de gestionar infraestructura propia. Evito Kubernetes o clusters de Kafka. Busco que los equipos se enfoquen en el producto, no en manejar infraestructura.
- **Serverless, donde haga sentido:** Uso Serverless (Lambda, SQS) para tr√°fico impredecible y masivo tratando de proteger costos. Uso contenedores en App Runner donde la latencia en *cold start* es cr√≠tica, evitando pagar *provisioned concurrency* en Lambda.
- **Developer Experience:** Busco reducir la complejidad mental del equipo (y la m√≠a) separando ciertos dominios y evitando cadenas de Lambdas dif√≠ciles de monitorear, entre otros.
- **Resiliencia por dise√±o:** Siempre desarrollo pensando en que las piezas van a fallar.
- **Compliance y Seguridad:** La protecci√≥n de datos (PII de menores) y el aislamiento entre escuelas √ü(Multi-tenant) se manejan a nivel infraestructura e IAM. Es inaceptable que un tenant vea datos de otro.
- **Simplicidad:** Trato de no hacer sobre ingenier√≠a, pero dejando margen para iteraciones cercanas.

**Assumptions clave:**
- **Usuarios:** 50 escuelas, ~5k estudiantes, horario escolar concentrado (8am-4pm)
- **Patrones:** Escritura batch nocturna, lecturas concentradas durante clases
- **Compliance:** PII de menores, retenci√≥n 3 a√±os, auditor√≠a gobierno
- **API Gobierno:** Inestable, rate-limited, timeout frecuente

## El Problema

Tres flujos cr√≠ticos con restricciones espec√≠ficas:

1. **Evaluaciones centralizadas** - p95 < 120ms durante horario escolar
2. **Sincronizaci√≥n trimestral** - API gubernamental inestable, 48h compliance deadline, trazabilidad total
3. **Perfil comportamental** - Picos 5k RPS, analytics hist√≥rico
**Restricci√≥n clave:** Multi-tenant strict con auditor√≠a real, sin fugas entre tenants.
## Arquitectura AWS - Vista Completa

```mermaid
flowchart TB
    subgraph Security["üîí Seguridad Externa"]
        WAF[WAF]
        Cognito[Cognito]
        IAM[IAM Roles]
    end
    
    subgraph Interactive["üöÄ Path 1: Interactivo"]
        APIG1[API Gateway]
        AppRunner[App Runner<br/>Auto-scaling]
    end
    
    subgraph HighVolume["üìä Path 2: Alta Velocidad"]
        APIG2[API Gateway<br/>Direct Integration]
        SQS[SQS Queue<br/>Anti-Stampede]
        ESM[Event Source<br/>Mapping]
        LambdaBatch[Lambda Workers<br/>Batch 50]
    end
    
    subgraph Government["üèõÔ∏è Path 3: Gobierno"]
        EventBridge[EventBridge<br/>Trimestral]
        StepFunctions[Step Functions<br/>Standard Workflow]
        DLQ[Dead Letter<br/>Queue]
    end
    
    subgraph Data["üíæ Datos"]
        DynamoDB[(DynamoDB<br/>Single Table<br/>On-Demand)]
        DDBStreams[DynamoDB<br/>Streams]
    end
    
    subgraph Pipeline["üîÑ Data Pipeline"]
        Pipes[EventBridge<br/>Pipes]
        Firehose[Kinesis<br/>Firehose]
        S3[(S3 Data Lake<br/>Partitioned)]
        Athena[Athena<br/>Analytics]
    end
    
    subgraph Monitoring["üìà Observabilidad"]
        CloudWatch[CloudWatch<br/>Logs + Metrics]
        XRay[X-Ray<br/>Tracing]
        CloudTrail[CloudTrail<br/>Audit]
        SNS[SNS Alerts]
    end
    
    %% Path 1: Interactive (Profesores)
    WAF --> APIG1
    Cognito --> IAM
    IAM --> AppRunner
    APIG1 --> AppRunner
    AppRunner --> DynamoDB
    
    %% Path 2: High Volume (Estudiantes)
    WAF --> APIG2
    APIG2 --> SQS
    SQS --> ESM
    ESM --> LambdaBatch
    LambdaBatch --> DynamoDB
    LambdaBatch --> DLQ
    
    %% Path 3: Government (Sistema)
    EventBridge --> StepFunctions
    StepFunctions --> DLQ
    
    DynamoDB --> DDBStreams
    DDBStreams --> Pipes
    Pipes --> Firehose
    Firehose --> S3
    S3 --> Athena
    
    AppRunner --> CloudWatch
    LambdaBatch --> XRay
    StepFunctions --> CloudTrail
    CloudWatch --> SNS
```

## Escenarios de Uso

Cada escenario demuestra las decisiones clave de latencia, seguridad, y operaci√≥n:

### Escenario 1: Profesora registra evaluaci√≥n (11:30am, clase activa)

**Flujo write cr√≠tico** - debe completar en <120ms para no interrumpir clase.

```mermaid
flowchart LR
    Prof[üë©‚Äçüè´ Profesora] -->|JWT school_id=123| WAF[WAF]
    WAF -->|DDoS + Rate Check| APIG[API Gateway]
    APIG -->|Validate JWT| AppRunner[App Runner<br/>Container Pool]
    AppRunner -->|Cached Config<br/>TCP Pool| DDB[(DynamoDB)]
    DDB -->|PutItem 15ms| AppRunner
    AppRunner -->|201 Created 45ms| Prof
    
    AppRunner -.->|Async| CW[CloudWatch]
    CW -.->|Alert if p95 > 120ms| SNS[SNS]
```

**Decisiones de latencia/escala:**
- **Connection pooling:** App Runner mantiene 10-25 TCP connections a DynamoDB (vs Lambda cold start)
- **Config caching:** Validation rules cached 5min in-memory, evita query extra
- **Read models:** Consolidated grades pre-calculados nocturnamente

**Multi-tenant security:**
- **IAM enforcement:** `dynamodb:LeadingKeys` policy fuerza PK = `school_id` del JWT
- **PII protection:** DynamoDB encryption at-rest + CloudTrail audit de cada write

**Monitoring completo:**
- **App Runner** ‚Üí **CloudWatch Logs** (structured logging con correlation ID)
- **CloudWatch Metrics** ‚Üí custom metric `EvaluationLatency` p95
- **CloudWatch Alarm** ‚Üí si p95 > 120ms por 2 minutos consecutivos
- **SNS Topic** ‚Üí email/SMS a equipo DevOps para scaling manual
- **Auto-scaling trigger** ‚Üí App Runner scales 1‚Üí3 instancias autom√°ticamente

**Trade-off:** App Runner vs ECS Fargate ‚Üí menos config, auto-scaling built-in

---

### Escenario 2: 5,000 estudiantes env√≠an eventos simult√°neos (recreo)

**Flujo anti-stampede** - absorber pico sin rechazar requests ni colapsar downstream.

```mermaid
flowchart TD
    Students[üë®‚Äçüéì 5k Estudiantes] -->|POST /behavior| APIG2[API Gateway<br/>Direct Integration]
    APIG2 -->|SendMessage<br/>No Lambda| SQS[SQS Queue<br/>Anti-Stampede]
    SQS -->|202 Accepted<br/>2ms| Students
    
    SQS -->|Batch 50 msgs<br/>or 5 sec| ESM[Event Source<br/>Mapping]
    ESM -->|20 concurrent| Lambda[Lambda Workers]
    Lambda -->|BatchWrite 25| DDB[(DynamoDB)]
    
    Lambda -.->|Failed 3x| DLQ[Dead Letter<br/>Queue]
    Lambda -.->|Metrics| CW[CloudWatch]
    CW -.->|Queue depth > 1K| SNS[Alert]
```

**Decisiones de latencia/escala:**
- **Anti-stampede:** SQS act√∫a como buffer infinito, absorbe 5k ‚Üí 100 RPS steady
- **Batch optimization:** 50:1 ratio reduce DynamoDB calls, $0.40 vs $2.00 por mill√≥n
- **Event-driven:** No polling, ESM trigger autom√°tico

**Operaci√≥n completa:**
- **SQS CloudWatch Metric:** `ApproximateNumberOfVisibleMessages` (queue depth)
- **Queue depth > 1000** significa: Lambda workers no procesan tan r√°pido como llegan eventos
- **CloudWatch Alarm:** `QueueDepthHigh` activo si depth > 1000 por 5 minutos
- **SNS notification:** Alerta a equipo para investigar bottleneck downstream
- **Posibles causas:** DynamoDB throttling, Lambda timeout, network issues
- **DLQ pattern:** Eventos que fallan 3x van a DLQ para debugging manual
- **Auto-scaling:** Lambda concurrency escala autom√°tico hasta 20 concurrent executions

**Trade-off:** Eventual consistency (OK para behavior events) vs real-time complexity

---

### Escenario 3: Sync trimestral con gobierno (API inestable)

**Flujo de m√°xima resiliencia** - debe completar en 48h con trazabilidad total.

```mermaid
stateDiagram-v2
    [*] --> QueryPending : EventBridge Trigger
    QueryPending --> PrepBatch : Found pending grades
    PrepBatch --> SendBatch : Create batch + UUID
    
    SendBatch --> WaitRate : HTTP 200 OK
    SendBatch --> Retry5s : HTTP 503/Timeout
    SendBatch --> ClientError : HTTP 4XX
    
    Retry5s --> SendBatch : Attempt 1
    Retry5s --> Retry15s : Max retries
    Retry15s --> SendBatch : Attempt 2
    Retry15s --> Retry45s : Max retries
    Retry45s --> SendBatch : Attempt 3
    Retry45s --> DLQ : Max retries (3x)
    
    WaitRate --> MarkSynced : Rate limit 2 req/sec
    MarkSynced --> QueryPending : Continue next batch
    
    ClientError --> QueryPending : Skip permanent errors
    DLQ --> ManualReview : Human intervention
    
    QueryPending --> Reconcile : All batches sent
    Reconcile --> [*] : Verify completeness
```

**Integraci√≥n gobierno (todos los requisitos de Jes√∫s):**
- **Idempotencia:** Batch UUID como header, API acepta duplicados safely
- **Rate limiting:** Max 2 requests/segundo para no sobrecargar API externo
- **Reintentos:** Exponential backoff 5s ‚Üí 15s ‚Üí 45s (network glitch ‚Üí server overload ‚Üí maintenance)
- **Reconciliaci√≥n:** Lambda final verifica que gobierno recibi√≥ todos los grades vs base local
- **Auditor√≠a:** Step Functions execution history + CloudTrail = trazabilidad completa

**Operaci√≥n (Step Functions son visibles en AWS Console):**
- **Visual debugging:** AWS Step Functions Console ‚Üí Execution History tab muestra exactamente qu√© batch fall√≥ y cu√°ndo
- **State machine definition:** JSON visible en Definition tab, editable via Code/Visual editor
- **Real-time execution:** Graph view muestra progreso actual: QueryPending ‚Üí SendBatch ‚Üí Retry5s, etc.
- **Manual intervention:** DLQ + SNS alert para casos que requieren revisi√≥n humana
- **Compliance:** 48h deadline met con retry autom√°tico + manual fallback

**Trade-off:** Step Functions vs Lambda custom ‚Üí state management declarativo, timeouts largos

---

### Escenario 4: Pipeline de datos para analytics

**Flujo hot/cold storage** - optimizar costo vs query performance.

```mermaid
flowchart LR
    DDB[(DynamoDB<br/>Hot 30 d√≠as)] -->|Streams| Pipes[EventBridge<br/>Pipes]
    Pipes -->|Filter + Transform| Firehose[Kinesis<br/>Firehose]
    Firehose -->|Parquet + GZIP<br/>1MB batches| S3[(S3 Data Lake<br/>Cold Storage)]
    S3 -->|Partitioned by<br/>year/month/school| Athena[Athena<br/>Analytics]
    
    Pipes -.->|Failed records| DLQ2[DLQ]
    Firehose -.->|Delivery metrics| CW2[CloudWatch]
```

**Decisiones de latencia/escala:**
- **Hot/cold separation:** DynamoDB TTL 30 d√≠as, S3 hist√≥rico = 90% cost reduction
- **Zero-code pipeline:** EventBridge Pipes + Firehose, no Lambda custom
- **Query optimization:** Parquet format + partitioning = 10x faster Athena queries

**Multi-tenant security:**
- **Data isolation:** S3 partitioned by school_id, IAM policies enforce access
- **Retention:** TTL autom√°tico en hot data, cold data retained 3 a√±os compliance

**Trade-off:** All DynamoDB vs Hot/Cold ‚Üí operational complexity pero massive cost savings

---

## Trade-offs por Componente

### **Arquitectura General**
- **H√≠brido compute vs uniformidad:** App Runner elimina cold starts para path interactivo (<120ms), Lambda para batch. Todo Lambda requerir√≠a $200/mes provisioned concurrency.

### **Base de Datos**  
- **DynamoDB single table vs PostgreSQL:** Sacrifico JOINs nativos pero gano 10-15ms menos latency + escalamiento instant√°neo. Aurora toma 30-45s en escalar durante picos.
- **On-demand vs provisioned:** Pago por uso real vs capacity planning. Tr√°fico educativo es spiky (8am-4pm), provisioned ser√≠a over o under.

### **Seguridad Multi-tenant**
- **IAM LeadingKeys vs app-level:** +20ms STS overhead pero garantiza que bug de c√≥digo no expone datos cross-tenant. Con PII de menores es inaceptable depender solo de WHERE clauses.
- **Defense-in-depth vs simplicidad:** M√°s configuraci√≥n IAM pero auditable a nivel infraestructura para compliance.

### **Integraci√≥n Gobierno**
- **Step Functions vs Lambda custom:** $10/a√±o vs $0 pero evito reimplementar retry/backoff/DLQ. API gobierno es inestable, necesito robustez battle-tested.
- **Visual debugging vs logs:** Workflow states visible en console vs parsear logs. Facilita debugging cuando sync falla.

### **Pipeline de Datos**
- **EventBridge Pipes vs Lambda processing:** Zero c√≥digo de mantenimiento vs control total. Filtro y transformaci√≥n declarativa vs 150+ l√≠neas custom.
- **Hot/Cold storage vs todo DynamoDB:** Queries <30 d√≠as en 10ms vs hist√≥rico en S3+Athena 2-5s. Ahorro masivo: $125 vs $13/mes.

### **Ingesta Alta Velocidad**
- **SQS buffer vs Lambda directo:** Eventual consistency (aceptable para behavior events) vs risk de throttling en 5k RPS spikes.
- **Batch 50 eventos vs individual:** +2s latency promedio pero 80% cost reduction en DynamoDB writes.

### **Observabilidad**
- **CloudWatch nativo vs Datadog/ELK:** Features b√°sicos pero integraci√≥n zero-config + $15/mes vs setup complejo + $200+/mes operational overhead.

**Tema consistente:** Elegir tecnolog√≠a aburrida que funciona, optimizada para patrones educativos (spiky, cost-sensitive, compliance-critical).

**Total: $45/mes vs $400+/mes alternativas**

---

